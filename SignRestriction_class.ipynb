{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Restriction Identification in Structural VARs\n",
    "\n",
    "This notebook implements SVAR identification using **sign restrictions** on impulse response functions.\n",
    "\n",
    "## Method: Rubio-Ramírez, Waggoner & Zha (2010)\n",
    "\n",
    "### Key Idea:\n",
    "Instead of imposing exact zero restrictions (like Blanchard-Quah), we identify shocks by imposing **inequality constraints** on IRFs:\n",
    "\n",
    "- **Supply shock**: GDP growth ↑, Inflation ↓\n",
    "- **Demand shock**: GDP growth ↑, Inflation ↑\n",
    "\n",
    "### Algorithm:\n",
    "1. Estimate reduced-form VAR → obtain variance-covariance matrix Ω\n",
    "2. Cholesky decomposition: Ω = P·P'\n",
    "3. For each draw:\n",
    "   - Generate random orthogonal matrix Q via QR decomposition\n",
    "   - Candidate identification: S = P·Q'\n",
    "   - Compute IRFs and check if sign restrictions are satisfied\n",
    "   - If yes, accept this identification\n",
    "4. Report distribution of accepted IRFs (set-identification)\n",
    "\n",
    "### References:\n",
    "- Rubio-Ramírez, J.F., Waggoner, D.F. & Zha, T. (2010). \"Structural Vector Autoregressions: Theory of Identification and Algorithms for Inference\", *Review of Economic Studies*, 77(2), 665-696.\n",
    "- Uhlig, H. (2005). \"What are the effects of monetary policy on output?\", *Journal of Monetary Economics*, 52(2), 381-419."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import fredapi\n",
    "\n",
    "# Install fredapi if needed:\n",
    "# !pip install fredapi\n",
    "\n",
    "FRED_API_KEY = ''  # Replace with your API key from https://fredaccount.stlouisfed.org/apikeys\n",
    "\n",
    "# Initialize FRED API\n",
    "fred = fredapi.Fred(api_key=FRED_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Core VAR Functions (reused from Blanchard-Quah notebook)\n",
    "\n",
    "def estimate_var(data, nlags, maxlags=None):\n",
    "    \"\"\"\n",
    "    Estimate a VAR(nlags) using OLS.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array of shape (nvars, T)\n",
    "        Variables in rows, time in columns\n",
    "    nlags : int\n",
    "        Number of lags in the VAR\n",
    "    maxlags : int, optional\n",
    "        Maximum number of lags to fix sample size\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with keys:\n",
    "        'coef': list of coefficient matrices\n",
    "        'intercept': constant term\n",
    "        'resid': residuals\n",
    "        'Omega': covariance matrix of residuals\n",
    "        'nobs', 'nlags', 'nvars'\n",
    "        'AIC', 'SIC', 'HQIC'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fix effective sample size\n",
    "    effective_lag = maxlags if maxlags is not None else nlags\n",
    "    \n",
    "    Y = data\n",
    "    T = Y.shape[1] - effective_lag\n",
    "    nvars = Y.shape[0]\n",
    "    \n",
    "    # Construct LHS and RHS (Lütkepohl notation)\n",
    "    Y_reg = Y[:, effective_lag:]\n",
    "    \n",
    "    X = np.ones((1, T))  # constant\n",
    "    for lag in range(1, nlags + 1):\n",
    "        X = np.vstack([X, Y[:, effective_lag-lag : effective_lag + T - lag]])\n",
    "    X_reg = X\n",
    "    \n",
    "    # OLS estimation\n",
    "    coef_all = Y_reg @ X_reg.T @ np.linalg.inv(X_reg @ X_reg.T)\n",
    "    \n",
    "    # Residuals and covariance\n",
    "    Y_fitted = coef_all @ X_reg\n",
    "    resid = Y_reg - Y_fitted\n",
    "    Omega = (resid @ resid.T) / T\n",
    "    \n",
    "    # Information criteria\n",
    "    log_det_Omega = np.log(np.linalg.det(Omega))\n",
    "    log_likelihood = -(T/2) * (nvars*np.log(2*np.pi) + nvars + log_det_Omega)\n",
    "    nv = nvars * (nvars*nlags + 1)\n",
    "    \n",
    "    AIC  = -2*log_likelihood + 2*nv\n",
    "    HQIC = -2*log_likelihood + 2*nv*np.log(np.log(T))\n",
    "    SIC  = -2*log_likelihood + nv*np.log(T)\n",
    "    \n",
    "    # Extract coefficients\n",
    "    intercept = coef_all[:, 0]\n",
    "    coef_matrices = []\n",
    "    for lag in range(nlags):\n",
    "        start_idx = 1 + lag * nvars\n",
    "        end_idx = 1 + (lag + 1) * nvars\n",
    "        coef_matrices.append(coef_all[:, start_idx:end_idx])\n",
    "    \n",
    "    return {\n",
    "        'coef': coef_matrices,\n",
    "        'intercept': intercept,\n",
    "        'resid': resid,\n",
    "        'Omega': Omega,\n",
    "        'nobs': T,\n",
    "        'nlags': nlags,\n",
    "        'nvars': nvars,\n",
    "        'log_likelihood': log_likelihood,\n",
    "        'AIC': AIC,\n",
    "        'SIC': SIC,\n",
    "        'HQIC': HQIC\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_impulse_response(var_results, nperiods=21, S=None):\n",
    "    \"\"\"\n",
    "    Compute impulse response functions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    var_results : dict\n",
    "        Output from estimate_var()\n",
    "    nperiods : int\n",
    "        Number of periods for IRFs\n",
    "    S : array, optional\n",
    "        Identification matrix. If None, uses Cholesky decomposition\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    irf : array of shape (nperiods, nvars, nvars)\n",
    "        irf[t, i, j] = response of variable i at time t to shock j\n",
    "    \"\"\"\n",
    "    \n",
    "    if S is None:\n",
    "        S = np.linalg.cholesky(var_results['Omega'])\n",
    "    \n",
    "    nlags = var_results['nlags']\n",
    "    nvars = var_results['nvars']\n",
    "    \n",
    "    # Companion form\n",
    "    companion_size = nvars * nlags\n",
    "    B_companion = np.zeros((companion_size, companion_size))\n",
    "    \n",
    "    for i in range(nlags):\n",
    "        start_col = i * nvars\n",
    "        end_col = (i + 1) * nvars\n",
    "        B_companion[:nvars, start_col:end_col] = var_results['coef'][i]\n",
    "    \n",
    "    if nlags > 1:\n",
    "        B_companion[nvars:, :nvars*(nlags-1)] = np.eye(nvars*(nlags-1))\n",
    "    \n",
    "    # Q matrix\n",
    "    Q = np.zeros((companion_size, nvars))\n",
    "    Q[:nvars, :] = S\n",
    "    \n",
    "    # Compute IRFs\n",
    "    irf = np.zeros((nperiods, nvars, nvars))\n",
    "    B_power = np.eye(companion_size)\n",
    "    \n",
    "    for t in range(nperiods):\n",
    "        Y_impact = B_power @ Q\n",
    "        irf[t, :, :] = Y_impact[:nvars, :].T\n",
    "        B_power = B_power @ B_companion\n",
    "    \n",
    "    return irf\n",
    "\n",
    "\n",
    "def compute_information_criteria(data, maxlags=8):\n",
    "    \"\"\"Compute AIC, SIC, HQC for lag selection.\"\"\"\n",
    "    \n",
    "    criteria = {'AIC': [], 'SIC': [], 'HQC': []}\n",
    "    \n",
    "    print(\"\\nInformation Criteria\")\n",
    "    print(\"====================\")\n",
    "    print(\"Lag    AIC      SIC      HQC\")\n",
    "    print(\"=================================\")\n",
    "    \n",
    "    for lag in range(1, maxlags + 1):\n",
    "        var_result = estimate_var(data, lag, maxlags)\n",
    "        \n",
    "        aic = var_result['AIC']\n",
    "        sic = var_result['SIC']\n",
    "        hqc = var_result['HQIC']\n",
    "        \n",
    "        criteria['AIC'].append(aic)\n",
    "        criteria['SIC'].append(sic)\n",
    "        criteria['HQC'].append(hqc)\n",
    "        \n",
    "        print(f\" {lag}  {aic:8.3f} {sic:8.3f} {hqc:8.3f}\")\n",
    "    \n",
    "    # Find optimal lags\n",
    "    opt_aic = np.argmin(criteria['AIC']) + 1\n",
    "    opt_sic = np.argmin(criteria['SIC']) + 1\n",
    "    opt_hqc = np.argmin(criteria['HQC']) + 1\n",
    "    \n",
    "    criteria['optimal_AIC'] = opt_aic\n",
    "    criteria['optimal_SIC'] = opt_sic\n",
    "    criteria['optimal_HQC'] = opt_hqc\n",
    "    \n",
    "    print(\"\\nOptimal number of lags:\")\n",
    "    print(\"======================\")\n",
    "    print(f\"AIC: {opt_aic}\")\n",
    "    print(f\"SIC: {opt_sic}\")\n",
    "    print(f\"HQC: {opt_hqc}\")\n",
    "    \n",
    "    return criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data Loading Functions\n",
    "\n",
    "def load_gdp_inflation_data(fred, start_date='1948-01-01', end_date='2019-10-01'):\n",
    "    \"\"\"\n",
    "    Load GDP and CPI data from FRED and compute growth rates.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fred : fredapi.Fred\n",
    "        FRED API object\n",
    "    start_date, end_date : str\n",
    "        Date range for data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    df : DataFrame\n",
    "        Contains GDP and CPI in levels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Download quarterly GDP (real)\n",
    "    gdp = fred.get_series('GDPC1').to_frame(name='gdp')\n",
    "    \n",
    "    # Download CPI (monthly) and convert to quarterly\n",
    "    cpi = fred.get_series('CPIAUCSL').to_frame(name='cpi')\n",
    "    cpi_q = cpi.resample('QS').mean()  # Average over quarter\n",
    "    \n",
    "    # Merge\n",
    "    df = pd.merge(gdp, cpi_q, left_index=True, right_index=True, how='inner')\n",
    "    \n",
    "    # Filter dates\n",
    "    df = df[(df.index >= start_date) & (df.index <= end_date)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_gdp_inflation_data(df):\n",
    "    \"\"\"\n",
    "    Compute GDP growth and inflation from levels.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    data : array of shape (2, T)\n",
    "        Row 0: GDP growth (log diff, annualized %)\n",
    "        Row 1: Inflation (log diff, annualized %)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Log differences (quarterly rates)\n",
    "    gdp_growth = np.log(df['gdp']).diff().dropna()\n",
    "    inflation = np.log(df['cpi']).diff().dropna()\n",
    "    \n",
    "    # Convert to annualized percentage points\n",
    "    gdp_growth = 400 * gdp_growth.values  # 4 quarters * 100%\n",
    "    inflation = 400 * inflation.values\n",
    "    \n",
    "    # Align (inflation calculated after GDP growth due to diff)\n",
    "    T = min(len(gdp_growth), len(inflation))\n",
    "    \n",
    "    data = np.array([gdp_growth[:T], inflation[:T]])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Sign Restriction Identification Functions\n",
    "\n",
    "def sign_restriction_identification(var_results, sign_restrictions, horizon=2, \n",
    "                                     max_draws=10000, nperiods=21, verbose=True):\n",
    "    \"\"\"\n",
    "    Identify structural shocks using sign restrictions.\n",
    "    \n",
    "    Algorithm: Rubio-Ramírez, Waggoner & Zha (2010)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    var_results : dict\n",
    "        Output from estimate_var()\n",
    "    sign_restrictions : list of dicts\n",
    "        Each dict has keys 'var_idx', 'shock_idx', 'sign', 'horizon'\n",
    "        Example: [{'var_idx': 0, 'shock_idx': 0, 'sign': '+'},\n",
    "                  {'var_idx': 1, 'shock_idx': 0, 'sign': '-'}]\n",
    "        means shock 0 increases var 0 and decreases var 1\n",
    "    horizon : int\n",
    "        Number of periods to enforce sign restrictions\n",
    "    max_draws : int\n",
    "        Maximum number of candidate rotations to try\n",
    "    nperiods : int\n",
    "        Total periods for IRFs to store\n",
    "    verbose : bool\n",
    "        Print progress\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    irf_accepted : array of shape (n_accepted, nperiods, nvars, nvars)\n",
    "        All IRFs that satisfy sign restrictions\n",
    "    acceptance_rate : float\n",
    "        Proportion of draws accepted\n",
    "    \"\"\"\n",
    "    \n",
    "    nvars = var_results['nvars']\n",
    "    \n",
    "    # Cholesky decomposition of Omega\n",
    "    P = np.linalg.cholesky(var_results['Omega'])\n",
    "    \n",
    "    irf_accepted = []\n",
    "    n_accepted = 0\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nSearching for valid identifications (max {max_draws} draws)...\")\n",
    "    \n",
    "    for draw in range(max_draws):\n",
    "        \n",
    "        if verbose and draw % 1000 == 0 and draw > 0:\n",
    "            print(f\"Draw {draw}/{max_draws} | Accepted: {n_accepted} ({100*n_accepted/draw:.1f}%)\")\n",
    "        \n",
    "        # Step 1: Generate random orthogonal matrix via QR decomposition\n",
    "        L = np.random.randn(nvars, nvars)\n",
    "        Q, R = np.linalg.qr(L)\n",
    "        \n",
    "        # Step 2: Normalize Q (ensure diagonal of R is positive)\n",
    "        for i in range(nvars):\n",
    "            if R[i, i] < 0:\n",
    "                Q[:, i] = -Q[:, i]\n",
    "        \n",
    "        # Step 3: Candidate identification matrix\n",
    "        S_candidate = P @ Q.T\n",
    "        \n",
    "        # Step 4: Compute IRFs for this candidate\n",
    "        irf_candidate = compute_impulse_response(var_results, nperiods, S_candidate)\n",
    "        \n",
    "        # Step 5: Check sign restrictions\n",
    "        if check_sign_restrictions(irf_candidate, sign_restrictions, horizon):\n",
    "            irf_accepted.append(irf_candidate)\n",
    "            n_accepted += 1\n",
    "    \n",
    "    if verbose:\n",
    "        acceptance_rate = n_accepted / max_draws\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Total draws: {max_draws}\")\n",
    "        print(f\"Accepted: {n_accepted}\")\n",
    "        print(f\"Acceptance rate: {100*acceptance_rate:.2f}%\")\n",
    "        print(f\"{'='*50}\\n\")\n",
    "    \n",
    "    if n_accepted == 0:\n",
    "        raise ValueError(\"No valid identifications found! Check your sign restrictions.\")\n",
    "    \n",
    "    return np.array(irf_accepted), acceptance_rate\n",
    "\n",
    "\n",
    "def check_sign_restrictions(irf, restrictions, horizon):\n",
    "    \"\"\"\n",
    "    Check if IRF satisfies all sign restrictions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    irf : array of shape (nperiods, nvars, nvars)\n",
    "        Impulse responses\n",
    "    restrictions : list of dicts\n",
    "        Sign restrictions to check\n",
    "    horizon : int\n",
    "        Number of periods to check\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bool : True if all restrictions satisfied\n",
    "    \"\"\"\n",
    "    \n",
    "    for restr in restrictions:\n",
    "        var_idx = restr['var_idx']\n",
    "        shock_idx = restr['shock_idx']\n",
    "        sign = restr['sign']\n",
    "        \n",
    "        # Check restriction for each period up to horizon\n",
    "        for h in range(horizon):\n",
    "            value = irf[h, shock_idx, var_idx]  # Note: irf[t, shock, var]\n",
    "            \n",
    "            if sign == '+' and value <= 0:\n",
    "                return False\n",
    "            elif sign == '-' and value >= 0:\n",
    "                return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Visualization Functions\n",
    "\n",
    "def plot_sign_restriction_irfs(irf_accepted, var_names=['GDP Growth', 'Inflation'],\n",
    "                                shock_names=['Supply Shock', 'Demand Shock'],\n",
    "                                percentiles=[5, 50, 95]):\n",
    "    \"\"\"\n",
    "    Plot all accepted IRFs with percentile bands.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    irf_accepted : array of shape (n_accepted, nperiods, nvars, nvars)\n",
    "        All accepted IRFs\n",
    "    var_names : list of str\n",
    "        Names of variables\n",
    "    shock_names : list of str\n",
    "        Names of shocks\n",
    "    percentiles : list of float\n",
    "        Percentiles to plot (default: 5th, 50th, 95th)\n",
    "    \"\"\"\n",
    "    \n",
    "    n_accepted, nperiods, nvars, nshocks = irf_accepted.shape\n",
    "    periods = np.arange(nperiods)\n",
    "    \n",
    "    fig, axes = plt.subplots(nvars, nshocks, figsize=(12, 8))\n",
    "    \n",
    "    if nvars == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, shock_name in enumerate(shock_names):\n",
    "        for j, var_name in enumerate(var_names):\n",
    "            \n",
    "            ax = axes[j, i]\n",
    "            \n",
    "            # Plot all accepted IRFs (light gray)\n",
    "            for k in range(n_accepted):\n",
    "                ax.plot(periods, irf_accepted[k, :, i, j],\n",
    "                       color='gray', alpha=0.05, linewidth=0.5)\n",
    "            \n",
    "            # Compute and plot percentiles\n",
    "            irf_percentiles = np.percentile(irf_accepted[:, :, i, j], percentiles, axis=0)\n",
    "            \n",
    "            # 5th and 95th percentiles (dashed)\n",
    "            ax.plot(periods, irf_percentiles[0], 'b--', linewidth=1.5, \n",
    "                   label=f'{percentiles[0]}th percentile')\n",
    "            ax.plot(periods, irf_percentiles[2], 'b--', linewidth=1.5,\n",
    "                   label=f'{percentiles[2]}th percentile')\n",
    "            \n",
    "            # Median (solid red)\n",
    "            ax.plot(periods, irf_percentiles[1], 'r-', linewidth=2.5,\n",
    "                   label='Median', zorder=10)\n",
    "            \n",
    "            # Formatting\n",
    "            ax.set_title(f'{var_name} → {shock_name}', fontsize=11)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.axhline(0, color='k', linestyle='-', linewidth=0.8, alpha=0.5)\n",
    "            ax.set_xlabel('Quarters')\n",
    "            ax.set_ylabel('Percentage points')\n",
    "            \n",
    "            # Legend only in top-left panel\n",
    "            if i == 0 and j == 0:\n",
    "                ax.legend(fontsize=8, loc='best')\n",
    "    \n",
    "    plt.suptitle(f'Impulse Responses with Sign Restrictions ({n_accepted} accepted models)',\n",
    "                fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_data(df, data):\n",
    "    \"\"\"Plot GDP growth and inflation time series.\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    \n",
    "    periods = pd.date_range(start=df.index[1], periods=data.shape[1], freq='QS')\n",
    "    \n",
    "    ax.plot(periods, data[0], 'b-', linewidth=1.5, label='GDP Growth (annual %)')\n",
    "    ax.plot(periods, data[1], 'r-', linewidth=1.5, label='Inflation (annual %)')\n",
    "    \n",
    "    ax.set_title('GDP Growth and Inflation', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Percent')\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axhline(0, color='k', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Main Analysis\n",
    "\n",
    "# Set date range\n",
    "start_date = '1955-01-01'\n",
    "end_date = '2019-10-01'\n",
    "\n",
    "print(\"Loading data from FRED...\")\n",
    "df = load_gdp_inflation_data(fred, start_date, end_date)\n",
    "\n",
    "print(\"Preparing data (computing growth rates)...\")\n",
    "data = prepare_gdp_inflation_data(df)\n",
    "\n",
    "print(f\"\\nData shape: {data.shape}\")\n",
    "print(f\"Variables: GDP growth, Inflation\")\n",
    "print(f\"Observations: {data.shape[1]}\")\n",
    "print(f\"Period: {start_date} to {end_date}\")\n",
    "\n",
    "# Plot data\n",
    "plot_data(df, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Estimate VAR\n",
    "\n",
    "# Check lag length\n",
    "criteria = compute_information_criteria(data, maxlags=8)\n",
    "\n",
    "# Estimate VAR with selected lag length\n",
    "nlags = 3  # Or use criteria['optimal_SIC']\n",
    "print(f\"\\nEstimating VAR({nlags})...\")\n",
    "\n",
    "var_results = estimate_var(data, nlags)\n",
    "\n",
    "print(f\"\\nVAR estimation complete:\")\n",
    "print(f\"  Number of observations: {var_results['nobs']}\")\n",
    "print(f\"  Number of variables: {var_results['nvars']}\")\n",
    "print(f\"  Number of lags: {var_results['nlags']}\")\n",
    "print(f\"  Log-likelihood: {var_results['log_likelihood']:.2f}\")\n",
    "print(f\"\\nCovariance matrix of residuals (Omega):\")\n",
    "print(var_results['Omega'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Apply Sign Restrictions\n",
    "\n",
    "# Define sign restrictions\n",
    "# Supply shock (shock 0): GDP ↑, Inflation ↓\n",
    "# Demand shock (shock 1): GDP ↑, Inflation ↑\n",
    "\n",
    "sign_restrictions = [\n",
    "    # Supply shock (shock 0)\n",
    "    {'var_idx': 0, 'shock_idx': 0, 'sign': '+'},  # GDP growth > 0\n",
    "    {'var_idx': 1, 'shock_idx': 0, 'sign': '-'},  # Inflation < 0\n",
    "    \n",
    "    # Demand shock restrictions can be added here if desired\n",
    "    # {'var_idx': 0, 'shock_idx': 1, 'sign': '+'},  # GDP growth > 0\n",
    "    # {'var_idx': 1, 'shock_idx': 1, 'sign': '+'},  # Inflation > 0\n",
    "]\n",
    "\n",
    "# Set parameters\n",
    "horizon = 2        # Enforce restrictions for first 2 quarters\n",
    "max_draws = 10000  # Try up to 10,000 random rotations\n",
    "nperiods = 21      # Compute IRFs for 21 quarters\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SIGN RESTRICTION IDENTIFICATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nSign restrictions (enforced for first {horizon} quarters):\")\n",
    "print(\"  Supply shock: GDP ↑, Inflation ↓\")\n",
    "print(\"  (Demand shock unrestricted)\")\n",
    "\n",
    "# Run identification\n",
    "irf_accepted, acceptance_rate = sign_restriction_identification(\n",
    "    var_results, \n",
    "    sign_restrictions, \n",
    "    horizon=horizon,\n",
    "    max_draws=max_draws,\n",
    "    nperiods=nperiods,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Visualize Results\n",
    "\n",
    "print(\"Plotting impulse response functions...\\n\")\n",
    "\n",
    "plot_sign_restriction_irfs(\n",
    "    irf_accepted,\n",
    "    var_names=['GDP Growth', 'Inflation'],\n",
    "    shock_names=['Supply Shock', 'Demand Shock'],\n",
    "    percentiles=[5, 50, 95]\n",
    ")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Number of accepted models: {irf_accepted.shape[0]}\")\n",
    "print(f\"Acceptance rate: {100*acceptance_rate:.2f}%\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(\"  - Gray lines: All models consistent with sign restrictions\")\n",
    "print(\"  - Dashed blue: 90% confidence band (5th-95th percentiles)\")\n",
    "print(\"  - Red line: Median response across all accepted models\")\n",
    "print(\"\\nNote: This is SET identification - multiple structural models\")\n",
    "print(\"      are consistent with the data and sign restrictions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
